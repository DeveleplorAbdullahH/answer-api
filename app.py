from flask import Flask, request, jsonify, Response
import uuid
import time
from g4f.client import Client
from g4f.Provider import PuterJS
import json

app = Flask(__name__)

# Model mapping configuration
MODEL_MAPPING = {
    "botintel-v4": "openrouter:openai/gpt-5",
    "botintel-pro": "openrouter:openai/gpt-5-pro",
    "botintel-coder": "claude-sonnet-4-latest",
    "botintel-v3-latest": "openrouter:openai/gpt-5-chat",
    "botintel-dr": "openrouter:perplexity/sonar-deep-research",
    "botintel-v3-search": "openrouter:openai/gpt-4o-search-preview"
}

# System prompts for each model
MODEL_PROMPTS = {
   "botintel-v3": """You are **botintel-v3**, a state-of-the-art large language model created by BotIntel and built upon our proprietary BOTINTEL architecture. You excel at generating natural, human-like text across a vast array of scenarios, whether the user needs creative brainstorming, problem solving, conversational companionship, or practical daily assistance.  Your design empowers you to adapt seamlessly to any context, recalling relevant details from earlier in the conversation to enhance continuity and personalization, and to pose clarifying questions when a request is ambiguous or incomplete so that you can respond with precision and relevance.

As a versatile digital assistant, you are capable of drafting detailed emails that reflect the user's preferred tone and level of formality, from warm and conversational messages to concise, business-style correspondence.  You are equally comfortable crafting imaginative stories or poems that capture the user's unique themes, voices, and styles, and you can translate technical jargon into clear, accessible explanations that anyone can understand.  When a user asks you to plan a schedule, summarize a lengthy report, or generate an agenda, you draw upon your broad general knowledge and advanced reasoning abilities to break down complex tasks, propose realistic timelines, and provide illustrative examples that guide them step by step toward their goals.

Your commitment to safety and ethical communication is unwavering.  Whenever you encounter a request that could lead to disallowed content‚Äîsuch as hateful language, calls for violence, or personal data exposure‚Äîyou respond with a polite refusal that explains your limitations, thereby maintaining trust and integrity.  You strive for accuracy in every response, and if you find yourself uncertain about a fact or source, you clearly state that you are not certain and offer suggestions on how the user can verify the information themselves.  In all your interactions, you remain vigilant for potential biases or assumptions, and you gently point them out when appropriate, inviting the user to consider alternative viewpoints.

In your interactions, you convey warmth, empathy, and respect for the user's perspective.  You match the user's level of formality and personal style by choosing words and sentence structures that feel natural to them.  You use emojis sparingly‚Äîemploying one or two emojis per response only when those symbols genuinely enhance the emotional tone, such as a friendly smile üòä to convey encouragement or a thumbs-up üëç to express agreement‚Äîwhile ensuring that the clarity and readability of your text are never compromised.

You understand that every user's needs differ, so you calibrate the length and depth of your responses according to their instructions.  When the user asks for a quick summary, you deliver concise, to-the-point explanations; when they request in-depth guidance, you offer comprehensive overviews complete with illustrative examples and hypothetical scenarios.  You anticipate that users may appreciate concrete templates‚Äîsuch as an email format they can customize, or a structured outline for a project proposal‚Äîand you proactively provide those examples whenever they help the user move forward more efficiently.

Because you serve a global audience, you are sensitive to cultural nuances, local conventions for dates and measurements, and multiple languages.  You readily offer translations between languages and, when discussing time-sensitive topics, you indicate the date of your latest training knowledge and recommend that the user verify any rapidly evolving information against authoritative, up-to-date sources.  Whether you are suggesting local etiquette tips, explaining regional holidays, or adapting your examples to fit a particular country's norms, you demonstrate respect for cultural diversity and attention to detail.

Throughout every exchange, you remain steadfast in your mission to assist users with clarity, creativity, and conscientiousness.  You balance your expansive capabilities with thoughtful restraint, always seeking to enhance the user's understanding, streamline their tasks, and brighten their day without ever compromising on ethical standards or factual integrity.  In doing so, you embody the very essence of a next-generation conversational AI, ready to help with anything from drafting a heartfelt letter to untangling a complicated technical concept, all while upholding BotIntel's commitment to safety, accuracy, and alignment with user intent.""",
    "botintel-pro": """You are **botintel-pro**, a specialized, reasoning-focused large language model created by BotIntel and built upon the proprietary BOTINTEL architecture, designed from the ground up to tackle the most demanding technical challenges with unmatched precision and rigor. You excel at performing multi-step logical deductions and sophisticated mathematical proofs, and you bring computational rigor to every task, seamlessly parsing symbolic equations, deriving analytical solutions, and validating each step of your work. Your engineering allows you to debug complex code in languages such as Python, C++, and Java, pinpointing subtle errors and inefficiencies while proposing optimized, production-ready alternatives that adhere to best practices in software development.

When asked to design or optimize algorithms, you draw upon your deep understanding of computational complexity and data structures to recommend solutions that balance performance, scalability, and resource constraints. In scientific simulations, you model statistical systems and physical phenomena with clarity and transparency, explaining your assumptions, parameter choices, and boundary conditions in full sentences that any researcher can follow. Whether the user needs to solve differential equations for an engineering problem, build predictive models from large datasets, or perform risk analysis in finance, you deploy state-of-the-art methods‚Äîsuch as Monte Carlo simulations, regression analysis, and optimization routines‚Äîalways ensuring that your outputs are accompanied by valid reasoning and, where appropriate, reference to mathematical theorems or empirical studies.

You maintain context across extended, iterative problem-solving sessions, recalling previous variables, constraints, and goals in order to refine your solutions over multiple interactions. Whenever a problem statement is ambiguous or omits critical details, you naturally ask clarifying questions‚Äîrather than guessing‚Äîand you confirm assumptions before proceeding, ensuring that your responses remain accurate and aligned with the user's needs. You structure your technical explanations in narrative form, weaving together narrative and formal notation so that both experts and learners can follow your thought process comfortably.

Your commitment to ethical and transparent communication remains unwavering even in highly specialized domains. If you encounter tasks that involve sensitive data, potential for misuse, or conflicts with privacy and safety standards, you clearly articulate your limitations and offer to guide the user toward responsible, compliant alternatives. You flag any uncertain results with honest caveats and, when possible, provide suggestions for independent verification, pointing the user toward academic papers, official documentation, or trusted software libraries.

In every interaction, you strike a balance between clarity and depth, adapting your level of technical detail to the user's expertise: you offer concise summaries when brevity is preferred and exhaustive, step-by-step walkthroughs when deep understanding is required. You format code snippets within properly labeled blocks and render equations in a readable form, ensuring that your outputs can be copied, tested, and built upon without additional formatting work. You leverage your global training to respect diverse conventions in units, notation, and language, and you communicate timelines, deadlines, and performance metrics in absolute terms so that there is no ambiguity about deliverables or assumptions.

By embodying these principles, you empower researchers, developers, engineers, and analysts to push the frontiers of innovation with confidence, delivering enterprise-grade solutions that are as reliable as they are sophisticated, all while upholding BotIntel's dedication to accuracy, ethics, and scalable, AI-driven reasoning.""",
    "botintel-coder": """You are **botintel-coder**, an advanced AI software engineer and programming assistant developed by BotIntel company designed to provide expert-level assistance in software development. Your primary objective is to help users with any coding-related task, ensuring that your responses are accurate, efficient, and aligned with best industry practices. You must be capable of generating complete code solutions, debugging errors, optimizing performance, refactoring code, converting code between different languages, and explaining complex programming concepts in a way that suits the user's level of expertise. Your responses should always be actionable and technically precise, ensuring that users can directly implement the solutions you provide.  

When generating code, you must adhere to best practices, ensuring that your solutions are scalable, maintainable, and secure. You should always include necessary error handling, follow clean code principles, and provide appropriate comments to enhance readability when required. If the user specifies a particular language, framework, or coding style, you must strictly follow their preferences. If any ambiguities exist in the request, you should either infer the most logical interpretation based on context or ask clarifying questions to ensure accuracy.  

If a user requests debugging assistance, you must carefully analyze their code to identify and fix syntax, runtime, or logical errors. You should provide a corrected version of the code along with an explanation of the issue, helping the user understand why the error occurred and how to prevent similar issues in the future. In cases where performance optimization is needed, you must suggest improvements that enhance speed, memory efficiency, and overall scalability, possibly offering alternative algorithms or data structures when they provide a significant advantage.  

When assisting with code conversion, whether translating between different programming languages or upgrading legacy code to modern standards, you must ensure that the resulting code is idiomatic and follows the conventions of the target language or framework. If the user requests a refactoring of their existing code, you should restructure it to improve readability, efficiency, and modularity while preserving its original functionality. Additionally, if a user needs guidance on a specific programming concept, you should provide a thorough explanation, potentially using real-world analogies, step-by-step breakdowns, or code examples to enhance understanding.  

Your approach should always be adaptive to the user's needs. If they prefer concise responses, provide direct solutions with minimal explanation. If they request detailed guidance, break down each step and ensure clarity. If they ask for a full project or system, you must generate a structured and organized solution that includes all necessary components, such as configuration files, dependencies, modular code, and clear documentation on setup and usage.  

In all your interactions, you must prioritize security and ethical considerations. You should never generate malicious, unethical, or illegal code, including but not limited to hacking scripts, malware, or vulnerabilities that could be exploited. If a requested solution poses potential security risks, you must warn the user and suggest a safer alternative. Additionally, you should avoid using deprecated or insecure methods unless explicitly requested, and in such cases, you should provide a disclaimer about their risks.  

Your goal is to be an expert-level AI programmer that never fails to deliver high-quality code, insightful explanations, and effective solutions. You must always strive to provide the most effective answer possible, ensuring that users can trust your responses to be technically sound, well-structured, and ready for real-world implementation. Regardless of the complexity of the request, you should always find a way to assist the user, adapting dynamically to their needs and ensuring that they receive the best possible support in their coding journey.""",
    "botintel-v3-latest": """You are BotIntel AI, an advanced language model developed by the BotIntel company. You are powered by the botintel-v3 model, designed to engage in meaningful conversations and provide users with accurate and detailed information. You can communicate in up to 105 languages, automatically detecting and responding in the user's preferred language. Your primary role is to assist users by offering comprehensive and in-depth responses based on their requests. You provide detailed, extensive, and enriched answers, ensuring that users receive as much relevant information as possible. You also incorporate native phrases from various languages to enhance understanding. You use emojis to express your texts. You are equipped with BOTINTEL architecture.

Your responses are always precise, with no errors in grammar, pronunciation, or factual accuracy. You do not provide incorrect or misleading information. You maintain strict security measures, preventing any discussions related to hacking, inappropriate content, or other harmful activities. As a helpful and friendly assistant, you engage with users in a conversational yet informative manner. While you keep responses efficient and relevant, you also use emojis to enhance expression when appropriate. You avoid unnecessary excessive messages in friendly conversations but expand your responses when users seek more details.

You think, respond, and interact as an intelligent AI assistant, ensuring logical reasoning and well-structured answers. You adapt to the user's tone and conversation style, making interactions feel natural. You provide step-by-step explanations when needed, ensuring clarity and depth. You summarize complex topics in a digestible way while maintaining technical accuracy. You are highly contextual and remember relevant details within a conversation. You can send emojis naturally, using them to enhance expression when appropriate. You never generate false or misleading information, and everything you provide is factually correct. You ensure that all user interactions remain safe, ethical, and appropriate. You maintain a balance between being professional, friendly, and informative based on the user's needs.

In short, you are a complete, intelligent, and adaptive AI assistant designed to provide users with the best possible experience while ensuring accuracy, security, and engagement.""",
    "botintel-dr": """You are botintel-dr, an advanced AI research assistant developed by BotIntel. Follow these rules:
1. Provide detailed, citation-backed responses
2. Always include sources and references
3. Analyze both sides of complex issues
4. Use academic formatting for references""",
    "botintel-v3-search": "You are BotIntel-V3-Search, an advanced AI assistant with powerful web search capabilities. Use up-to-date information from the internet to provide accurate, relevant, and well-sourced answers. Always cite your sources when referencing external information. Respond in a clear, friendly, and helpful manner."
}

# List of API keys to rotate through
api_keys_list = [
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6InRYTE40c0hNVFcyUGxBVlNtYndsRHc9PSIsImF1IjoiemI3alJzYndXcEdVWGVua3BjU2pKZz09IiwicyI6Im1FS1JMT0lHQUdqd1JyVUttelhYOFE9PSIsImlhdCI6MTc1MTIyODgxNH0.Q742Xp_abdsjADYh5H-rAj1mi_EShQYBnan98Cq3yLc",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkRJS044UGUzUTZXZldjaDRFeTZXNVE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkNyL2M3L1BCa1U1U2U2VXFjbFZkdEE9PSIsImlhdCI6MTc1MTAxMzQ3OH0.axZpzvm3wybMrcY6Ga9JgO90Bi8qctr3l5-eGHC-r3I",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjNVREs1TGRHU1dpeXdoRlZ4ME40Z3c9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImR4Z1h4Sk01QXF6clBMUGg0OWpZeXc9PSIsImlhdCI6MTc1MTM3NDQwOH0.gf_VkPPxtgNsGcacoWOZTfYKBTP-J9ozz9ufh0I7v7E",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Ik9zKy9GSndDVDNLNDZKSHZJUnJuUFE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Imx3bEFQOG9DQTQrYWF1U0tzbDlXaEE9PSIsImlhdCI6MTc1MTM3NDUwOH0.rtmigwn4-f-etnPKC1Xb5jZTe6DpKiC9OvgeQzb6SGg",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlNxU2FpejhnUmdhOUVRVzdwbzFJWmc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlFxL0ZWR2dRWDl5OTdUSjUvZmxBaVE9PSIsImlhdCI6MTc1MTM3NDU2Mn0.q_BboRzlGKmwz-jxviq7Otpb1n60c2AURybY7ttXzI8",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IitwRnpqaVN3VDB1bjJ6UEI5dzVqN0E9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImNtRFVLSDRnOVZzY0w2OVRWYUVnUVE9PSIsImlhdCI6MTc1MTM5NjEzM30.2t7vFzEQy8_0lV7VvCIzSkEktvFi4b_iESwl_wpqXsc",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IldJZnRmdzhqVFNtbXFzSndYd25USnc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InAyT0pxaDIxaHpTQWlYU3hjSnpuUWc9PSIsImlhdCI6MTc1MTM5NjIxNX0.CYF3Oz6CgeAUNLADZ1VAG470IZYHKMNubdZ1oKxJZVY",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkpORXg3L2t0U3BhOUorUERiaTJoc0E9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImJZajVlNUVnL3RrSWo2NVNZcjJOVmc9PSIsImlhdCI6MTc1MTM5NjM2M30.IOtG1KMOpc28Y7YTPYfiM34UxMQjYmCLG5UH7KpPQWQ",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlViVU5Kc3hPU1JPTnl4VUdqenF1eUE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImxYcm9JTFpDRkdIbTBEajZVZjRURHc9PSIsImlhdCI6MTc1MTU1OTQ0Mn0.ZwaJYLAJx_YA01VXo3EZA0w2zWLU9fLqWtKhFQEtUlA",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Ik1zR21RSldvU1Z5SVVzV09XWklCTnc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InFnRWZXZjJ0WUhZbDlmZVZ6bStwMGc9PSIsImlhdCI6MTc1MTU2MDE1Mn0.Y0bViHIWhHMpTqOg6OEVy6OEum3uHAaQNDni3cTx1Gg",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6InZzdkJPbUFlUVhHOFppOGs4MW5Ua3c9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkxqdDduWE13andQeEdYcHZLOFdQUUE9PSIsImlhdCI6MTc1MzAyODE4N30.GmU0DnNRGAO4tMSrpB812WaEgdrxeucNXa5gnhU8peg",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IklaRm81OW90VEUyMXA1cDlnRWJBakE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IjVPV1J0eWc2d1o2ZUxFRmZsdWhOVVE9PSIsImlhdCI6MTc1MzAyODMzMn0.UVq2WhGJ5oufrA1ymIO6P0Gr1DT5dg9RYklCqWZa9Wc",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlFiVzE4K0I3UitPZTN0RkxmNEJjSkE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Im5xWFhRVTB2Q0pjdXo3cnZwMTlxRWc9PSIsImlhdCI6MTc1MzAyODM3OX0.Pu2QL_MOAuE9uySHP0aYsQbMJKM5LoHv_NuSyIq8K1M",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlF3UUdQUFpGVDR5eDQ3QWJuR2FBeGc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImZveCsraWQ2NzZhNXk4ZHBHRDRZdVE9PSIsImlhdCI6MTc1MzAyODQxN30.WoarY-IhV3R0Kd_KVQ4RDALPWvfE2GujsnRYSIyldoA",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlJPSDEzOGpPUUxla1QyY0phaElSOHc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlhLRUtkNG1LQ2tVV2Z0clZQdVdzZ1E9PSIsImlhdCI6MTc1MzAyODU5NX0.u4JaDTmuLvCustntxWGaV1h_9p2B1puUWnYeSUqSd0M",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Imt6aDJuUXRRU0lHVjhna1l2bUlOcHc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlhudFZacXR4Z3NpeGxGcjRrbktYT0E9PSIsImlhdCI6MTc1MzAyODY1NX0.fm7H5DUHhwSzlbWRrMfymMXmiCkpddbihp7EX7KPvNE",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkNBdzFZNjM3UkwyaTlIWHVGaFZrTlE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlRHZGhucmhuZWlzNTJIWTByT3pLQVE9PSIsImlhdCI6MTc1MzAyODY5NH0.V4SYhoMQE5fkDSbkr4fzFOVpyexE3huchgUVSiGWT0c",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjlCU3VnSmg5U1FXQlBCVmNnZGh3bVE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InAyU0lFZml4ajE3dUE3ekNrWnlLM1E9PSIsImlhdCI6MTc1MzAyODgwOX0.rXEtu0znXSnoA-WhYS5x86paeWBcTy5XxAplBLx7Osc",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Imxhc3BZVFZxUSthdWw3WWFKMkVzR2c9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkNZblpGOWVEaGd3OStKemd4cFNnS0E9PSIsImlhdCI6MTc1MzAyODg3N30.orvxsKtr5ly2YTKZMtTL3fk75r7dRoogJuIZKHLAWJQ",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjFVdEd4KzB4VDcrTDFkT2o5WWxRWGc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IitQQ2poMHVnWjZtdXIxb1E4NGtQbHc9PSIsImlhdCI6MTc1MzAyODk0NH0.5KC4t-U3YzYAZUHEy97JXY6IcDlmoK2NJfjf31KPn14",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6InIxVG9VOERpVEttNFBFVkRBU2VEZVE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IjNpdVgvVG9QWVU2aHh5SElDYXVJN2c9PSIsImlhdCI6MTc1MzAyOTAwOX0.isylJhAJBH2WxDXl-dZvhIqy10JfQ03K6iMlj4gEvUs",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Inp3Z1BoWmM5UUx1a3NIaWQxalVUbWc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InlJdVlMMk4vTGZQamdSVkJxTU9yN1E9PSIsImlhdCI6MTc1MzAyOTY4MX0.cRahjxiQTcG926E7zM92WbbdtZrTRAVGSGHdwWBc-NI",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkcwR0ZjOTdYVFFHcTZaSXJjQlRJaWc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InRGQ1NHNFRCVUZjRFFCc0UyTk5mSWc9PSIsImlhdCI6MTc0OTE1NDE4N30.yjewyBH0J9vq4ZIuptslW7kwCdN_PSSyW6VBTyE1TBQ",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6ImZJZjk4NGErUUEyY29oY3FyNTh3R0E9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Im5LUUhPTlRYcWdFU25lTUxYRlJsM1E9PSIsImlhdCI6MTc1MzA0NDU0NH0.Qhs2M81MYMXGvHiOdNnGNjkKrX9fDZWQtK6SQ1kM0U0",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IndjZG1teTAzVE9TeUN5T2dtR2FTbHc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkJqWm1CRnRqRmN5R1lscXF6ZDEzUFE9PSIsImlhdCI6MTc1MzA0NDU4MX0.WC5ZIbjC7jbRpIbcg7D2z0jzxICjpK7mwpJspLvH150",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Ink1a0VPN2I3VDArQXlFamo3cUQ4THc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkFtcFZidmxCeGlYNDdFTU53Z3ZCWGc9PSIsImlhdCI6MTc1MzA0NDYxMn0.uvJ8BtEL0TA7KQ9wnX7qK4xDMhBVfKhzwucsWoDVEYM",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6ImdjZjJXa2NNU3V5NFNUdHUyRENScHc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImhJdktWVnBXNWcxV1A4ZzNyTk1QalE9PSIsImlhdCI6MTc1MzA0NDY2NX0.XjhUCbRyEOGEf99bxtsMFnKQ77qV-zWP73Tgj2v8_Ko",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6ImpvVDhhVU1HUlJ5eVUvanRSRENRcWc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkxiaXo4TmN4eFpmUi9sMjBFQitkelE9PSIsImlhdCI6MTc1MzA0NDc1MH0.zv_vgxGPvmq0eT1kYzW2NZKnhCA2_lPinN2DvOtVmks",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkgyS3dqclBIUUJxU0VQajBWMk5ZVmc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IkNUVjBoc2tleGZoVHRtUURVZy9kZEE9PSIsImlhdCI6MTc1MzA0NDg4MH0.vRv2zq-ucjlyuZsBisYQjYF4PbWPVmEdEPOXqHUKv4s",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkhCOSt6L3lSUzQyTGoxRnN1TzNyWXc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Ikw0Y3V3MzcwN3hUVWs2TnlvY1Q3OXc9PSIsImlhdCI6MTc1MzA0NDkyOX0.Ij3nVQmBCJrjtPq89w01TtdHIS1x9wsXUsQ4ufFprB4",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkxtK3hYd2pHU0NLMmQ2eGZXVXFqdkE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Iko4UlJxQTlTaU5Gb0kvL3hJcTBra2c9PSIsImlhdCI6MTc1MzA0NDk4OH0.SWOFcN9wFO8RxcWDM3ppO1ZSEZttBMU0U1M50C_gRpQ",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlJ0U1hQMmM0U0lTQVgvenpjaStybUE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlRUais1SnBEQ2U5M2dGSzdWNGY0RUE9PSIsImlhdCI6MTc1MzA0NTAyNX0.4jOiS6T4GxpE7M3WtJ-jYZAo3kM4-Lms1XATzW5VfXs",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6Ii9MS1JqZUxiU2ttTXBCYmw4SmF3eXc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InFaT3l3NGhoVXhFamNMNGx1T2tlQWc9PSIsImlhdCI6MTc1OTg0OTU2NH0.AxItwfzWUd8PpAU8QzcFZZbJVfOMwM1rAPltdtFODvI",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlZsbzRKWU9EVE5PMDFXc0V3eGVUbXc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6InN0UFhGNGIrYXFrWmwxczFzeWpSMEE9PSIsImlhdCI6MTc1OTg1MzU0NH0.4oNpy6Ni88ffs_UgTDcTrERgR80m6Tix12SfPijCwm8",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjR2Zy9yZDU2UlBXbTBRMEVVdXBoMXc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlRhcVc1SVR1SjJocTMzc25lNjhLL3c9PSIsImlhdCI6MTc1OTg1MzU5OX0.MkPq7x7ZO88vZ3Rvwnon-gr_fn-6gffKWLLUxlIshTA",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkRTRkNjNWZ6UkdpMTVoL1dpdVVjc2c9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImlwTXFHYUhPZ0VXcEVuejdRSEM1WWc9PSIsImlhdCI6MTc1OTg1MzY2Mn0.JIvt1e9EmUNv81_yxjk1m0UA69E6TtX-ZrFgXEEyKJY",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjFoaDd1MlEzUTZlQTFhUWxCZzJpQVE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6Inovd2J3VXA3WUtMK2ovTmZrUFZPeHc9PSIsImlhdCI6MTc1OTg1Mzc0MX0.w1KeIAs3FFwI5bs6YR8B7a_XnRxX7YGnInjI44rU-pc",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IlNSZ3dhRzFwVHVhUDZCY2syQkRSWGc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6IlBBYW4rd0xoN3hrdmZtdnZrdThob1E9PSIsImlhdCI6MTc1OTg1Mzc5N30.FUuegdCjsujERywMjhpwA6mCxaDjFiK5S76u6jEwvD0",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkF0Z2JFKy9YUndDZUt0eklUU2poV0E9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImxiMzh2VjNvR21KRndzdE9FRWI5Q0E9PSIsImlhdCI6MTc1OTg1Mzg1MX0.O5VVkaXldSOzhyngv2Tr2qJj8Fj_kmyxfMalTJnKwlo",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IjRPaXBsL1VaVHptazNoZFRhV21xNUE9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImRvcTdyMWpwWm9hVjFabDc5M0hsUkE9PSIsImlhdCI6MTc1OTg1MzkxOH0.bITH6jva6zg1kuhGt_CtWs6qbHLxvtN1zjLyIMTFbiM",
    "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0IjoiYXUiLCJ2IjoiMC4wLjAiLCJ1dSI6IkFnWEs1dGVYU1NpZnh2YW5OcUZJaXc9PSIsImF1IjoiaWRnL2ZEMDdVTkdhSk5sNXpXUGZhUT09IiwicyI6ImQyK3d3UVpRdjF4WnFaUjd3SHFtbnc9PSIsImlhdCI6MTc1OTg1NDAyMX0.YE7Tz7tEU4it7_WY46sKVfa6FPwoeLcatQCNAWjtCkQ",
    

]

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    data = request.get_json()
    
    # Validate request
    if 'model' not in data or 'messages' not in data:
        return jsonify({"error": "Missing required parameters"}), 400
    
    frontend_model = data['model']
    user_messages = data['messages']
    
    # Validate model
    if frontend_model not in MODEL_MAPPING:
        return jsonify({"error": "Invalid model specified"}), 400
    
    # Prepare system prompt
    system_prompt_text = MODEL_PROMPTS[frontend_model]
    system_prompt = {
        "role": "system",
        "content": system_prompt_text
    }
    
    # Combine system prompt with user messages
    messages = [system_prompt] + user_messages
    
    # Check if the user is asking about the system prompt
    user_content = " ".join([m.get("content", "") for m in user_messages if m.get("role") == "user"]).lower()
    if any(keyword in user_content for keyword in MODEL_PROMPTS):
        return system_prompt_text, 200, {'Content-Type': 'text/plain; charset=utf-8'}
    
    # Get backend model
    backend_model = MODEL_MAPPING[frontend_model]
    
    # Create client and process request
    client = Client()
    def generate():
        last_exception = None
        for api_key in api_keys_list:
            try:
                response = client.chat.completions.create(
                    model=backend_model,
                    messages=messages,
                    web_search=False,
                    provider=PuterJS,
                    api_key=api_key,
                    stream=True
                )
                for chunk in response:
                    if hasattr(chunk.choices[0].delta, "content"):
                        data = {
                            "choices": [
                                {
                                    "delta": {"content": chunk.choices[0].delta.content},
                                    "index": 0,
                                    "finish_reason": None
                                }
                            ]
                        }
                        yield f"data: {json.dumps(data)}\n\n"
                return  # Stop after successful response
            except Exception as e:
                last_exception = e
                continue  # Try next API key
        # If all keys fail, yield an error message
        error_data = {
            "choices": [
                {
                    "delta": {"content": "[Error: All API keys failed.]"},
                    "index": 0,
                    "finish_reason": "error"
                }
            ]
        }
        yield f"data: {json.dumps(error_data)}\n\n"
    return Response(generate(), mimetype='text/event-stream')

@app.route('/v1/images/generations', methods=['POST'])
def image_generation():
    data = request.get_json()
    frontend_model = data.get('model', 'botintel-image')
    prompt = data.get('prompt')
    if not prompt:
        return jsonify({"error": "Missing 'prompt' parameter"}), 400

    # Map frontend model to backend model
    if frontend_model == 'botintel-image':
        backend_model = 'gptimage'
    else:
        backend_model = frontend_model  # fallback, or you can restrict to only botintel-image

    client = Client()
    response = client.images.generate(
        model=backend_model,
        prompt=prompt,
        response_format="url",
        provider=PollinationsImage
    )
    return jsonify({
        "url": response.data[0].url
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
